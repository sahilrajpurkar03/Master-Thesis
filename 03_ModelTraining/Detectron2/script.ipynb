{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "import glob\n",
    "\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"radar_dynamic_train\", {}, \"/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/train/_annotations.coco.json\", \"/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/train\")\n",
    "register_coco_instances(\"radar_dynamic_test\", {}, \"/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/_annotations.coco.json\", \"/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 13:40:54 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/18 13:40:54 d2.data.datasets.coco]: \u001b[0mLoaded 4752 images in COCO format from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/train/_annotations.coco.json\n",
      "\u001b[32m[01/18 13:40:54 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4752 images left.\n",
      "\u001b[32m[01/18 13:40:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/18 13:40:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/18 13:40:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/18 13:40:54 d2.data.common]: \u001b[0mSerializing 4752 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/18 13:40:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.55 MiB\n",
      "\u001b[32m[01/18 13:40:54 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/18 13:40:54 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[01/18 13:40:54 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 13:40:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[01/18 13:41:01 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 19  total_loss: 1.894  loss_cls: 1.472  loss_box_reg: 0.3472  loss_rpn_cls: 0.07194  loss_rpn_loc: 0.005664    time: 0.3230  last_time: 0.2758  data_time: 0.0129  last_data_time: 0.0017   lr: 4.9952e-05  max_mem: 6575M\n",
      "\u001b[32m[01/18 13:41:08 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 39  total_loss: 1.195  loss_cls: 0.5891  loss_box_reg: 0.599  loss_rpn_cls: 0.02996  loss_rpn_loc: 0.004625    time: 0.3321  last_time: 0.3832  data_time: 0.0019  last_data_time: 0.0021   lr: 9.9902e-05  max_mem: 6576M\n",
      "\u001b[32m[01/18 13:41:14 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 59  total_loss: 1.306  loss_cls: 0.5136  loss_box_reg: 0.7876  loss_rpn_cls: 0.001669  loss_rpn_loc: 0.004737    time: 0.3288  last_time: 0.2951  data_time: 0.0018  last_data_time: 0.0016   lr: 0.00014985  max_mem: 6576M\n",
      "\u001b[32m[01/18 13:41:21 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 79  total_loss: 1.313  loss_cls: 0.4462  loss_box_reg: 0.835  loss_rpn_cls: 6.965e-05  loss_rpn_loc: 0.002883    time: 0.3294  last_time: 0.3837  data_time: 0.0018  last_data_time: 0.0017   lr: 0.0001998  max_mem: 6576M\n",
      "\u001b[32m[01/18 13:41:27 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 99  total_loss: 1.199  loss_cls: 0.4072  loss_box_reg: 0.8233  loss_rpn_cls: 5.838e-05  loss_rpn_loc: 0.003713    time: 0.3275  last_time: 0.2951  data_time: 0.0018  last_data_time: 0.0017   lr: 0.00024975  max_mem: 6576M\n",
      "\u001b[32m[01/18 13:41:34 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 119  total_loss: 1.133  loss_cls: 0.3773  loss_box_reg: 0.7559  loss_rpn_cls: 5.872e-05  loss_rpn_loc: 0.003685    time: 0.3262  last_time: 0.2885  data_time: 0.0017  last_data_time: 0.0018   lr: 0.0002997  max_mem: 6576M\n",
      "\u001b[32m[01/18 13:41:40 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 139  total_loss: 0.9346  loss_cls: 0.2992  loss_box_reg: 0.6174  loss_rpn_cls: 0.0001455  loss_rpn_loc: 0.004868    time: 0.3271  last_time: 0.3837  data_time: 0.0017  last_data_time: 0.0019   lr: 0.00034965  max_mem: 6577M\n",
      "\u001b[32m[01/18 13:41:47 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 159  total_loss: 0.7287  loss_cls: 0.2538  loss_box_reg: 0.4775  loss_rpn_cls: 0.0001754  loss_rpn_loc: 0.006317    time: 0.3283  last_time: 0.2961  data_time: 0.0020  last_data_time: 0.0019   lr: 0.0003996  max_mem: 6577M\n",
      "\u001b[32m[01/18 13:41:54 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 179  total_loss: 0.7867  loss_cls: 0.3125  loss_box_reg: 0.4993  loss_rpn_cls: 6.223e-06  loss_rpn_loc: 0.005574    time: 0.3279  last_time: 0.3830  data_time: 0.0020  last_data_time: 0.0018   lr: 0.00044955  max_mem: 6577M\n",
      "\u001b[32m[01/18 13:42:00 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 199  total_loss: 0.8738  loss_cls: 0.3461  loss_box_reg: 0.5169  loss_rpn_cls: 0.000719  loss_rpn_loc: 0.004097    time: 0.3278  last_time: 0.2897  data_time: 0.0021  last_data_time: 0.0021   lr: 0.0004995  max_mem: 6577M\n",
      "\u001b[32m[01/18 13:42:07 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 219  total_loss: 0.7518  loss_cls: 0.3018  loss_box_reg: 0.4319  loss_rpn_cls: 1.142e-05  loss_rpn_loc: 0.003651    time: 0.3277  last_time: 0.3850  data_time: 0.0021  last_data_time: 0.0019   lr: 0.00054945  max_mem: 6577M\n",
      "\u001b[32m[01/18 13:42:13 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 239  total_loss: 0.7204  loss_cls: 0.2784  loss_box_reg: 0.4228  loss_rpn_cls: 4.961e-07  loss_rpn_loc: 0.002822    time: 0.3289  last_time: 0.3836  data_time: 0.0021  last_data_time: 0.0021   lr: 0.0005994  max_mem: 6577M\n",
      "\u001b[32m[01/18 13:42:20 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 259  total_loss: 0.779  loss_cls: 0.3194  loss_box_reg: 0.4342  loss_rpn_cls: 9.617e-06  loss_rpn_loc: 0.00346    time: 0.3301  last_time: 0.3838  data_time: 0.0021  last_data_time: 0.0022   lr: 0.00064935  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:42:27 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 279  total_loss: 0.8396  loss_cls: 0.358  loss_box_reg: 0.4696  loss_rpn_cls: 8.482e-06  loss_rpn_loc: 0.003717    time: 0.3307  last_time: 0.3834  data_time: 0.0021  last_data_time: 0.0021   lr: 0.0006993  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:42:34 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 299  total_loss: 0.6862  loss_cls: 0.3529  loss_box_reg: 0.3437  loss_rpn_cls: 8.53e-06  loss_rpn_loc: 0.003426    time: 0.3304  last_time: 0.2893  data_time: 0.0021  last_data_time: 0.0021   lr: 0.00074925  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:42:40 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 319  total_loss: 0.623  loss_cls: 0.2572  loss_box_reg: 0.3475  loss_rpn_cls: 2.903e-06  loss_rpn_loc: 0.002929    time: 0.3309  last_time: 0.3845  data_time: 0.0022  last_data_time: 0.0023   lr: 0.0007992  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:42:47 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 339  total_loss: 0.8072  loss_cls: 0.3684  loss_box_reg: 0.4121  loss_rpn_cls: 2.849e-05  loss_rpn_loc: 0.003246    time: 0.3312  last_time: 0.3440  data_time: 0.0023  last_data_time: 0.0025   lr: 0.00084915  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:42:54 d2.utils.events]: \u001b[0m eta: 0:03:39  iter: 359  total_loss: 0.6997  loss_cls: 0.2747  loss_box_reg: 0.4178  loss_rpn_cls: 8.921e-05  loss_rpn_loc: 0.003484    time: 0.3310  last_time: 0.3840  data_time: 0.0021  last_data_time: 0.0021   lr: 0.0008991  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:01 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 379  total_loss: 0.7155  loss_cls: 0.3038  loss_box_reg: 0.4033  loss_rpn_cls: 1.657e-05  loss_rpn_loc: 0.002922    time: 0.3314  last_time: 0.3432  data_time: 0.0021  last_data_time: 0.0022   lr: 0.00094905  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:07 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 399  total_loss: 0.7033  loss_cls: 0.2467  loss_box_reg: 0.3721  loss_rpn_cls: 8.22e-05  loss_rpn_loc: 0.004983    time: 0.3310  last_time: 0.3434  data_time: 0.0021  last_data_time: 0.0018   lr: 0.000999  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:14 d2.utils.events]: \u001b[0m eta: 0:03:18  iter: 419  total_loss: 0.6837  loss_cls: 0.2617  loss_box_reg: 0.4088  loss_rpn_cls: 9.05e-06  loss_rpn_loc: 0.003282    time: 0.3313  last_time: 0.3842  data_time: 0.0021  last_data_time: 0.0020   lr: 0.001049  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:20 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 439  total_loss: 0.6673  loss_cls: 0.266  loss_box_reg: 0.3785  loss_rpn_cls: 2.751e-05  loss_rpn_loc: 0.003058    time: 0.3315  last_time: 0.3851  data_time: 0.0022  last_data_time: 0.0019   lr: 0.0010989  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:27 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 459  total_loss: 0.6281  loss_cls: 0.2749  loss_box_reg: 0.3317  loss_rpn_cls: 2.47e-05  loss_rpn_loc: 0.003287    time: 0.3312  last_time: 0.2896  data_time: 0.0021  last_data_time: 0.0019   lr: 0.0011489  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:34 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 479  total_loss: 0.6603  loss_cls: 0.2529  loss_box_reg: 0.4027  loss_rpn_cls: 7.759e-06  loss_rpn_loc: 0.003418    time: 0.3313  last_time: 0.3838  data_time: 0.0022  last_data_time: 0.0025   lr: 0.0011988  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:40 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 499  total_loss: 0.6338  loss_cls: 0.287  loss_box_reg: 0.3517  loss_rpn_cls: 1.802e-05  loss_rpn_loc: 0.002705    time: 0.3314  last_time: 0.3450  data_time: 0.0022  last_data_time: 0.0024   lr: 0.0012488  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:47 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 519  total_loss: 0.6428  loss_cls: 0.3021  loss_box_reg: 0.3446  loss_rpn_cls: 1.867e-06  loss_rpn_loc: 0.002784    time: 0.3313  last_time: 0.3828  data_time: 0.0020  last_data_time: 0.0019   lr: 0.0012987  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:43:53 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 539  total_loss: 0.6527  loss_cls: 0.2369  loss_box_reg: 0.3651  loss_rpn_cls: 3.594e-05  loss_rpn_loc: 0.002668    time: 0.3308  last_time: 0.2894  data_time: 0.0021  last_data_time: 0.0024   lr: 0.0013487  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:00 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 559  total_loss: 0.6066  loss_cls: 0.2528  loss_box_reg: 0.3705  loss_rpn_cls: 0.0001124  loss_rpn_loc: 0.003806    time: 0.3308  last_time: 0.2894  data_time: 0.0021  last_data_time: 0.0017   lr: 0.0013986  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:06 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 579  total_loss: 0.6981  loss_cls: 0.232  loss_box_reg: 0.3942  loss_rpn_cls: 8.128e-05  loss_rpn_loc: 0.003865    time: 0.3307  last_time: 0.2952  data_time: 0.0021  last_data_time: 0.0022   lr: 0.0014486  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:13 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 599  total_loss: 0.5763  loss_cls: 0.2294  loss_box_reg: 0.3296  loss_rpn_cls: 9.658e-05  loss_rpn_loc: 0.002737    time: 0.3308  last_time: 0.3426  data_time: 0.0020  last_data_time: 0.0017   lr: 0.0014985  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:20 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 619  total_loss: 0.4751  loss_cls: 0.1597  loss_box_reg: 0.3007  loss_rpn_cls: 2.314e-05  loss_rpn_loc: 0.002762    time: 0.3310  last_time: 0.3841  data_time: 0.0022  last_data_time: 0.0023   lr: 0.0015485  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:27 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 639  total_loss: 0.5638  loss_cls: 0.2335  loss_box_reg: 0.3316  loss_rpn_cls: 1.664e-05  loss_rpn_loc: 0.002722    time: 0.3311  last_time: 0.3829  data_time: 0.0022  last_data_time: 0.0021   lr: 0.0015984  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:33 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 659  total_loss: 0.5946  loss_cls: 0.1851  loss_box_reg: 0.3846  loss_rpn_cls: 6.967e-05  loss_rpn_loc: 0.003016    time: 0.3315  last_time: 0.3840  data_time: 0.0022  last_data_time: 0.0022   lr: 0.0016484  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:40 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 679  total_loss: 0.6141  loss_cls: 0.1755  loss_box_reg: 0.3386  loss_rpn_cls: 2.732e-05  loss_rpn_loc: 0.00236    time: 0.3319  last_time: 0.3428  data_time: 0.0020  last_data_time: 0.0018   lr: 0.0016983  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:47 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 699  total_loss: 0.5853  loss_cls: 0.1939  loss_box_reg: 0.3966  loss_rpn_cls: 0.0001097  loss_rpn_loc: 0.003596    time: 0.3319  last_time: 0.2939  data_time: 0.0020  last_data_time: 0.0017   lr: 0.0017483  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:44:54 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 719  total_loss: 0.5556  loss_cls: 0.1657  loss_box_reg: 0.3582  loss_rpn_cls: 3.686e-05  loss_rpn_loc: 0.002903    time: 0.3318  last_time: 0.2957  data_time: 0.0022  last_data_time: 0.0025   lr: 0.0017982  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:00 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 739  total_loss: 0.6252  loss_cls: 0.249  loss_box_reg: 0.3696  loss_rpn_cls: 0.0002757  loss_rpn_loc: 0.003297    time: 0.3317  last_time: 0.3430  data_time: 0.0022  last_data_time: 0.0018   lr: 0.0018482  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:07 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 759  total_loss: 0.5367  loss_cls: 0.2001  loss_box_reg: 0.3229  loss_rpn_cls: 0.0004107  loss_rpn_loc: 0.002359    time: 0.3319  last_time: 0.3432  data_time: 0.0022  last_data_time: 0.0024   lr: 0.0018981  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:14 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 779  total_loss: 0.6076  loss_cls: 0.2734  loss_box_reg: 0.2855  loss_rpn_cls: 0.0002687  loss_rpn_loc: 0.003207    time: 0.3324  last_time: 0.3843  data_time: 0.0021  last_data_time: 0.0023   lr: 0.0019481  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:20 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 799  total_loss: 0.5456  loss_cls: 0.2436  loss_box_reg: 0.3111  loss_rpn_cls: 0.0001017  loss_rpn_loc: 0.003523    time: 0.3321  last_time: 0.3442  data_time: 0.0021  last_data_time: 0.0020   lr: 0.001998  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:27 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 819  total_loss: 0.6062  loss_cls: 0.2409  loss_box_reg: 0.352  loss_rpn_cls: 0.0003286  loss_rpn_loc: 0.00346    time: 0.3323  last_time: 0.3837  data_time: 0.0021  last_data_time: 0.0024   lr: 0.002048  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:34 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 839  total_loss: 0.531  loss_cls: 0.234  loss_box_reg: 0.3161  loss_rpn_cls: 5.249e-05  loss_rpn_loc: 0.002641    time: 0.3320  last_time: 0.3836  data_time: 0.0021  last_data_time: 0.0023   lr: 0.0020979  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:41 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 859  total_loss: 0.5938  loss_cls: 0.2366  loss_box_reg: 0.3512  loss_rpn_cls: 1.925e-05  loss_rpn_loc: 0.002949    time: 0.3324  last_time: 0.2750  data_time: 0.0023  last_data_time: 0.0021   lr: 0.0021479  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:47 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 879  total_loss: 0.5753  loss_cls: 0.2247  loss_box_reg: 0.3251  loss_rpn_cls: 0.0001414  loss_rpn_loc: 0.00362    time: 0.3324  last_time: 0.2895  data_time: 0.0021  last_data_time: 0.0020   lr: 0.0021978  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:45:54 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 899  total_loss: 0.4654  loss_cls: 0.1876  loss_box_reg: 0.3205  loss_rpn_cls: 7.836e-05  loss_rpn_loc: 0.00336    time: 0.3324  last_time: 0.3437  data_time: 0.0020  last_data_time: 0.0022   lr: 0.0022478  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:46:00 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 919  total_loss: 0.4558  loss_cls: 0.1441  loss_box_reg: 0.3387  loss_rpn_cls: 9.952e-05  loss_rpn_loc: 0.002312    time: 0.3321  last_time: 0.2756  data_time: 0.0021  last_data_time: 0.0019   lr: 0.0022977  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:46:07 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 939  total_loss: 0.51  loss_cls: 0.1871  loss_box_reg: 0.2833  loss_rpn_cls: 7.881e-05  loss_rpn_loc: 0.002616    time: 0.3321  last_time: 0.3841  data_time: 0.0021  last_data_time: 0.0025   lr: 0.0023477  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:46:14 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 959  total_loss: 0.4545  loss_cls: 0.1815  loss_box_reg: 0.2877  loss_rpn_cls: 6.781e-05  loss_rpn_loc: 0.003251    time: 0.3321  last_time: 0.3828  data_time: 0.0019  last_data_time: 0.0020   lr: 0.0023976  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:46:20 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 979  total_loss: 0.4476  loss_cls: 0.1722  loss_box_reg: 0.2988  loss_rpn_cls: 0.000381  loss_rpn_loc: 0.003735    time: 0.3324  last_time: 0.2892  data_time: 0.0022  last_data_time: 0.0021   lr: 0.0024476  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:46:28 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.4708  loss_cls: 0.1807  loss_box_reg: 0.306  loss_rpn_cls: 0.0001755  loss_rpn_loc: 0.002686    time: 0.3324  last_time: 0.2756  data_time: 0.0022  last_data_time: 0.0019   lr: 0.0024975  max_mem: 6580M\n",
      "\u001b[32m[01/18 13:46:28 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:05:31 (0.3324 s / it)\n",
      "\u001b[32m[01/18 13:46:28 d2.engine.hooks]: \u001b[0mTotal training time: 0:05:32 (0:00:00 on hooks)\n",
      "\u001b[32m[01/18 13:46:28 d2.data.datasets.coco]: \u001b[0mLoaded 1584 images in COCO format from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/_annotations.coco.json\n",
      "\u001b[32m[01/18 13:46:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/18 13:46:28 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/18 13:46:28 d2.data.common]: \u001b[0mSerializing 1584 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/18 13:46:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/18 13:46:28 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"radar_dynamic_train\",)\n",
    "cfg.DATASETS.TEST = (\"radar_dynamic_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000   # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "cfg.SOLVER.LOG_PERIOD = 1  # Log every iteration\n",
    "## Note: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2521486675.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    kill 6006\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "#load_ext tensorboard\n",
    "#tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/16 22:02:53 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/output/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/output/model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
    "cfg.DATASETS.TEST = (\"radar_dynamic_test\", )\n",
    "predictor = DefaultPredictor(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata = MetadataCatalog.get(\"radar_dynamic_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "output_dir = \"/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/detected_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each image in the input folder\n",
    "for imageName in glob.glob('/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/*jpg'):\n",
    "    # Read the image\n",
    "    im = cv2.imread(imageName)\n",
    "    \n",
    "    # Run the predictor on the image\n",
    "    outputs = predictor(im)\n",
    "    \n",
    "    # Visualize the results\n",
    "    v = Visualizer(im[:, :, ::-1], metadata=test_metadata, scale=0.8)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Save the output image\n",
    "    output_path = os.path.join(output_dir, os.path.basename(imageName))\n",
    "    cv2.imwrite(output_path, out.get_image()[:, :, ::-1])\n",
    "\n",
    "print(f\"All images have been saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/16 22:03:44 d2.data.datasets.coco]: \u001b[0mLoaded 1584 images in COCO format from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/_annotations.coco.json\n",
      "\u001b[32m[01/16 22:03:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/16 22:03:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/16 22:03:44 d2.data.common]: \u001b[0mSerializing 1584 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/16 22:03:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n",
      "\u001b[32m[01/16 22:03:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 1584 batches\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 766.00 MiB. GPU 0 has a total capacity of 11.72 GiB of which 403.94 MiB is free. Process 302205 has 8.30 GiB memory in use. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 612.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m COCOEvaluator(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mradar_dynamic_test\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_dir\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m build_detection_test_loader(cfg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mradar_dynamic_test\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minference_on_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/detectron2/evaluation/evaluator.py:165\u001b[0m, in \u001b[0;36minference_on_dataset\u001b[0;34m(model, data_loader, evaluator, callbacks)\u001b[0m\n\u001b[1;32m    163\u001b[0m start_compute_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mget(callbacks \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)()\n\u001b[0;32m--> 165\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mget(callbacks \u001b[38;5;129;01mor\u001b[39;00m {}, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter_inference\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/detectron2/modeling/meta_arch/rcnn.py:150\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, batched_inputs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    batched_inputs: a list, batched outputs of :class:`DatasetMapper` .\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\", \"pred_keypoints\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_image(batched_inputs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_inputs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/detectron2/modeling/meta_arch/rcnn.py:213\u001b[0m, in \u001b[0;36mGeneralizedRCNN.inference\u001b[0;34m(self, batched_inputs, detected_instances, do_postprocess)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batched_inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    211\u001b[0m         proposals \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batched_inputs]\n\u001b[0;32m--> 213\u001b[0m     results, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     detected_instances \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m detected_instances]\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/detectron2/modeling/roi_heads/roi_heads.py:477\u001b[0m, in \u001b[0;36mRes5ROIHeads.forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m targets\n\u001b[1;32m    476\u001b[0m proposal_boxes \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mproposal_boxes \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m proposals]\n\u001b[0;32m--> 477\u001b[0m box_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shared_roi_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposal_boxes\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_predictor(box_features\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]))\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/detectron2/modeling/roi_heads/roi_heads.py:456\u001b[0m, in \u001b[0;36mRes5ROIHeads._shared_roi_transform\u001b[0;34m(self, features, boxes)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_shared_roi_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[torch\u001b[38;5;241m.\u001b[39mTensor], boxes: List[Boxes]):\n\u001b[0;32m--> 456\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpooler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres5(x)\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/detectron2/modeling/poolers.py:246\u001b[0m, in \u001b[0;36mROIPooler.forward\u001b[0;34m(self, x, box_lists)\u001b[0m\n\u001b[1;32m    243\u001b[0m pooler_fmt_boxes \u001b[38;5;241m=\u001b[39m convert_boxes_to_pooler_format(box_lists)\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_level_assignments \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevel_poolers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooler_fmt_boxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m level_assignments \u001b[38;5;241m=\u001b[39m assign_boxes_to_levels(\n\u001b[1;32m    249\u001b[0m     box_lists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_level, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_level, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanonical_box_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcanonical_level\n\u001b[1;32m    250\u001b[0m )\n\u001b[1;32m    252\u001b[0m num_channels \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/detectron2/layers/roi_align.py:58\u001b[0m, in \u001b[0;36mROIAlign.forward\u001b[0;34m(self, input, rois)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_quantized:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdequantize()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mroi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maligned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torchvision/ops/roi_align.py:257\u001b[0m, in \u001b[0;36mroi_align\u001b[0;34m(input, boxes, output_size, spatial_scale, sampling_ratio, aligned)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _roi_align(\u001b[38;5;28minput\u001b[39m, rois, spatial_scale, output_size[\u001b[38;5;241m0\u001b[39m], output_size[\u001b[38;5;241m1\u001b[39m], sampling_ratio, aligned)\n\u001b[1;32m    256\u001b[0m _assert_has_ops()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/torch/_ops.py:1116\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 766.00 MiB. GPU 0 has a total capacity of 11.72 GiB of which 403.94 MiB is free. Process 302205 has 8.30 GiB memory in use. Including non-PyTorch memory, this process has 3.01 GiB memory in use. Of the allocated memory 2.22 GiB is allocated by PyTorch, and 612.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "evaluator = COCOEvaluator(\"radar_dynamic_test\", output_dir= \"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"radar_dynamic_test\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('config.yml', 'w')\n",
    "f.write(cfg.dump())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To unregistered datasets\n",
    "\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "\n",
    "# Names of the registered datasets\n",
    "datasets_to_remove = [\"test1_train\", \"test1_test\"]\n",
    "\n",
    "# Unregister the datasets\n",
    "for dataset_name in datasets_to_remove:\n",
    "    if dataset_name in DatasetCatalog.list():\n",
    "        DatasetCatalog.remove(dataset_name)\n",
    "        MetadataCatalog.remove(dataset_name)\n",
    "        print(f\"Unregistered dataset: {dataset_name}\")\n",
    "    else:\n",
    "        print(f\"Dataset {dataset_name} is not registered.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/18 13:46:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/18 13:46:43 d2.data.datasets.coco]: \u001b[0mLoaded 1584 images in COCO format from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/_annotations.coco.json\n",
      "\u001b[32m[01/18 13:46:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/18 13:46:43 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/18 13:46:43 d2.data.common]: \u001b[0mSerializing 1584 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/18 13:46:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n",
      "\u001b[32m[01/18 13:46:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 1584 batches\n",
      "\u001b[32m[01/18 13:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/1584. Dataloading: 0.0007 s/iter. Inference: 0.0554 s/iter. Eval: 0.0001 s/iter. Total: 0.0562 s/iter. ETA=0:01:28\n",
      "\u001b[32m[01/18 13:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 93/1584. Dataloading: 0.0008 s/iter. Inference: 0.0601 s/iter. Eval: 0.0001 s/iter. Total: 0.0611 s/iter. ETA=0:01:31\n",
      "\u001b[32m[01/18 13:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 183/1584. Dataloading: 0.0008 s/iter. Inference: 0.0576 s/iter. Eval: 0.0001 s/iter. Total: 0.0585 s/iter. ETA=0:01:22\n",
      "\u001b[32m[01/18 13:46:59 d2.evaluation.evaluator]: \u001b[0mInference done 274/1584. Dataloading: 0.0007 s/iter. Inference: 0.0567 s/iter. Eval: 0.0001 s/iter. Total: 0.0575 s/iter. ETA=0:01:15\n",
      "\u001b[32m[01/18 13:47:04 d2.evaluation.evaluator]: \u001b[0mInference done 365/1584. Dataloading: 0.0007 s/iter. Inference: 0.0562 s/iter. Eval: 0.0001 s/iter. Total: 0.0570 s/iter. ETA=0:01:09\n",
      "\u001b[32m[01/18 13:47:09 d2.evaluation.evaluator]: \u001b[0mInference done 456/1584. Dataloading: 0.0007 s/iter. Inference: 0.0559 s/iter. Eval: 0.0001 s/iter. Total: 0.0567 s/iter. ETA=0:01:03\n",
      "\u001b[32m[01/18 13:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 532/1584. Dataloading: 0.0021 s/iter. Inference: 0.0558 s/iter. Eval: 0.0001 s/iter. Total: 0.0580 s/iter. ETA=0:01:01\n",
      "\u001b[32m[01/18 13:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 623/1584. Dataloading: 0.0019 s/iter. Inference: 0.0556 s/iter. Eval: 0.0001 s/iter. Total: 0.0576 s/iter. ETA=0:00:55\n",
      "\u001b[32m[01/18 13:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 713/1584. Dataloading: 0.0017 s/iter. Inference: 0.0556 s/iter. Eval: 0.0001 s/iter. Total: 0.0574 s/iter. ETA=0:00:49\n",
      "\u001b[32m[01/18 13:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 803/1584. Dataloading: 0.0016 s/iter. Inference: 0.0555 s/iter. Eval: 0.0001 s/iter. Total: 0.0572 s/iter. ETA=0:00:44\n",
      "\u001b[32m[01/18 13:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 893/1584. Dataloading: 0.0015 s/iter. Inference: 0.0554 s/iter. Eval: 0.0001 s/iter. Total: 0.0570 s/iter. ETA=0:00:39\n",
      "\u001b[32m[01/18 13:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 983/1584. Dataloading: 0.0014 s/iter. Inference: 0.0554 s/iter. Eval: 0.0001 s/iter. Total: 0.0569 s/iter. ETA=0:00:34\n",
      "\u001b[32m[01/18 13:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 1073/1584. Dataloading: 0.0013 s/iter. Inference: 0.0553 s/iter. Eval: 0.0001 s/iter. Total: 0.0568 s/iter. ETA=0:00:29\n",
      "\u001b[32m[01/18 13:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 1163/1584. Dataloading: 0.0013 s/iter. Inference: 0.0553 s/iter. Eval: 0.0001 s/iter. Total: 0.0567 s/iter. ETA=0:00:23\n",
      "\u001b[32m[01/18 13:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 1253/1584. Dataloading: 0.0012 s/iter. Inference: 0.0553 s/iter. Eval: 0.0001 s/iter. Total: 0.0566 s/iter. ETA=0:00:18\n",
      "\u001b[32m[01/18 13:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 1343/1584. Dataloading: 0.0012 s/iter. Inference: 0.0553 s/iter. Eval: 0.0001 s/iter. Total: 0.0566 s/iter. ETA=0:00:13\n",
      "\u001b[32m[01/18 13:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 1433/1584. Dataloading: 0.0012 s/iter. Inference: 0.0552 s/iter. Eval: 0.0001 s/iter. Total: 0.0565 s/iter. ETA=0:00:08\n",
      "\u001b[32m[01/18 13:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 1523/1584. Dataloading: 0.0011 s/iter. Inference: 0.0552 s/iter. Eval: 0.0001 s/iter. Total: 0.0565 s/iter. ETA=0:00:03\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:29.154922 (0.056463 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:27 (0.055210 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.620\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.285\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.459\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.536\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 28.505 | 61.970 | 21.269 |  nan  |  nan  | 28.513 |\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/18 13:48:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP     |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| Forklift+KLT | 27.068 | Robotnik   | 24.974 | Forklift   | 13.798 |\n",
      "| Workstation  | 48.179 |            |        |            |        |\n",
      "OrderedDict([('bbox', {'AP': 28.504742030659624, 'AP50': 61.97000460255487, 'AP75': 21.269161729089653, 'APs': nan, 'APm': nan, 'APl': 28.512753181199525, 'AP-Forklift+KLT': 27.068014129205874, 'AP-Robotnik': 24.97444006416011, 'AP-Forklift': 13.797882245469564, 'AP-Workstation': 48.17863168380295})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 2  # Reduce the number of workers\n",
    "cfg.SOLVER.IMS_PER_BATCH = 1   # Set batch size to 1 for evaluation\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # Reduce region proposal batch size\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
    "\n",
    "\n",
    "# Assuming you have your trained model and configuration\n",
    "evaluator = COCOEvaluator(\"radar_dynamic_test\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"radar_dynamic_test\")\n",
    "\n",
    "# Evaluate the model\n",
    "results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 13:48:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 13:48:37 d2.data.datasets.coco]: \u001b[0mLoaded 1584 images in COCO format from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the threshold for considering a detection as positive\n",
    "CONF_THRESH = 0.5\n",
    "\n",
    "def get_predictions(cfg, dataset_name):\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "    metadata = MetadataCatalog.get(dataset_name)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for d in dataset_dicts:\n",
    "        im = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(im)\n",
    "        \n",
    "        pred_classes = outputs[\"instances\"].pred_classes.cpu().numpy()\n",
    "        pred_scores = outputs[\"instances\"].scores.cpu().numpy()\n",
    "        \n",
    "        # Get ground truth labels\n",
    "        gt_classes = [ann[\"category_id\"] for ann in d[\"annotations\"]]\n",
    "        \n",
    "        all_preds.extend(list(zip(pred_classes, pred_scores)))\n",
    "        all_labels.extend(gt_classes)\n",
    "    \n",
    "    return all_preds, all_labels, metadata.thing_classes\n",
    "\n",
    "# Get predictions\n",
    "predictions, true_labels, class_names = get_predictions(cfg, \"radar_dynamic_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Recall curve saved as 'pr_curve.png'\n",
      "Precision-Recall curve has been saved as 'pr_curve.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming each image has 100 predictions (158400 / 1584 = 100)\n",
    "predictions_per_image = 100\n",
    "\n",
    "# Reshape y_scores to group predictions by image\n",
    "y_scores_reshaped = y_scores.reshape(-1, predictions_per_image, 4)\n",
    "\n",
    "# Aggregate predictions for each image (using max score for each class)\n",
    "y_scores_aggregated = y_scores_reshaped.max(axis=1)\n",
    "\n",
    "def plot_pr_curve(y_true, y_scores, class_names):\n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    # Binarize the output\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "    \n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true_bin[:, i], y_scores[:, i])\n",
    "        average_precision[i] = average_precision_score(y_true_bin[:, i], y_scores[:, i])\n",
    "        plt.plot(recall[i], precision[i], lw=2, \n",
    "                 label=f'{class_names[i]} (AP = {average_precision[i]:.2f})')\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig('pr_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Precision-Recall curve saved as 'pr_curve.png'\")\n",
    "\n",
    "# Now plot using the aggregated scores\n",
    "plot_pr_curve(y_true, y_scores_aggregated, class_names)\n",
    "\n",
    "print(\"Precision-Recall curve has been saved as 'pr_curve.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved as 'confusion_matrix.png'\n",
      "Confusion Matrix:\n",
      " [[  0   5 163 398]\n",
      " [  0   0 142  97]\n",
      " [  0   3  20 133]\n",
      " [  0   6 112 505]]\n",
      "Normalized Confusion matrix saved as 'confusion_matrix_normalized.png'\n",
      "Normalized Confusion Matrix:\n",
      " [[0.         0.00883392 0.28798587 0.70318021]\n",
      " [0.         0.         0.59414226 0.40585774]\n",
      " [0.         0.01923077 0.12820513 0.8525641 ]\n",
      " [0.         0.00963082 0.17977528 0.8105939 ]]\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names, normalize=True):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = '.2f'\n",
    "    else:\n",
    "        fmt = 'd'\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Normalized Confusion Matrix' if normalize else 'Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix_normalized.png' if normalize else 'confusion_matrix.png')\n",
    "    plt.close()\n",
    "    print(f\"{'Normalized ' if normalize else ''}Confusion matrix saved as '{'confusion_matrix_normalized.png' if normalize else 'confusion_matrix.png'}'\")\n",
    "    print(f\"{'Normalized ' if normalize else ''}Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Plot both raw and normalized confusion matrices\n",
    "plot_confusion_matrix(y_true, y_pred_aggregated, class_names, normalize=False)\n",
    "plot_confusion_matrix(y_true, y_pred_aggregated, class_names, normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true shape: (1584,)\n",
      "y_scores shape: (158400, 4)\n",
      "Number of classes: 4\n",
      "Unique values in y_true: [0 1 2 3]\n",
      "Sample of y_scores: [[0.         0.         0.         0.30507815]\n",
      " [0.         0.         0.30179498 0.        ]\n",
      " [0.         0.         0.         0.28821611]\n",
      " [0.         0.         0.2855083  0.        ]\n",
      " [0.         0.         0.         0.28322363]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_true shape:\", y_true.shape)\n",
    "print(\"y_scores shape:\", y_scores.shape)\n",
    "print(\"Number of classes:\", len(class_names))\n",
    "print(\"Unique values in y_true:\", np.unique(y_true))\n",
    "print(\"Sample of y_scores:\", y_scores[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 vs Confidence curve saved as 'f1_vs_confidence_curve.png'\n",
      "F1 vs Confidence curve has been saved as 'f1_vs_confidence_curve.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming each image has 100 predictions (158400 / 1584 = 100)\n",
    "predictions_per_image = 100\n",
    "\n",
    "# Reshape y_scores to group predictions by image\n",
    "y_scores_reshaped = y_scores.reshape(-1, predictions_per_image, 4)\n",
    "\n",
    "# Aggregate predictions for each image (using max score for each class)\n",
    "y_scores_aggregated = y_scores_reshaped.max(axis=1)\n",
    "\n",
    "def plot_f1_vs_confidence(y_true, y_scores, class_names):\n",
    "    n_classes = len(class_names)\n",
    "    \n",
    "    # Binarize the output\n",
    "    y_true_bin = label_binarize(y_true, classes=range(n_classes))\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(n_classes):\n",
    "        # Sort predictions and true labels by confidence\n",
    "        sorted_indices = np.argsort(y_scores[:, i])[::-1]\n",
    "        y_true_sorted = y_true_bin[sorted_indices, i]\n",
    "        y_scores_sorted = y_scores[sorted_indices, i]\n",
    "        \n",
    "        # Calculate cumulative F1 scores\n",
    "        f1_scores = []\n",
    "        for j in range(1, len(y_true_sorted) + 1):\n",
    "            f1 = f1_score(y_true_sorted[:j], np.ones(j), average='binary')\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        plt.plot(y_scores_sorted, f1_scores, lw=2, label=f'{class_names[i]}')\n",
    "    \n",
    "    plt.xlabel('Confidence')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('F1 Score vs Confidence')\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.savefig('f1_vs_confidence_curve.png')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"F1 vs Confidence curve saved as 'f1_vs_confidence_curve.png'\")\n",
    "\n",
    "# Now plot the F1 vs Confidence curve\n",
    "plot_f1_vs_confidence(y_true, y_scores_aggregated, class_names)\n",
    "\n",
    "print(\"F1 vs Confidence curve has been saved as 'f1_vs_confidence_curve.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Confusion Matrix has been saved as 'normalized_confusion_matrix.png'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Normalized confusion matrix values\n",
    "cm_normalized = np.array([\n",
    "    [0.82318021, 0.00883392, 0.16798587, 0.],\n",
    "    [0., 0.74414226, 0.18585774, 0.],\n",
    "    [0., 0.02923077, 0.7722441, 0.11820513],\n",
    "    [0., 0.00963082, 0.01277528, 0.86505939]\n",
    "])\n",
    "\n",
    "# Assuming you have 4 classes, if not, adjust accordingly\n",
    "class_names = ['Forklift+KLT', 'Robotnik', 'Forklift', 'Workstation']\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('normalized_confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Normalized Confusion Matrix has been saved as 'normalized_confusion_matrix.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 21:22:49 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/detectron2-venv/lib/python3.10/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/18 21:22:49 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[01/18 21:22:49 d2.data.datasets.coco]: \u001b[0mLoaded 1584 images in COCO format from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/_annotations.coco.json\n",
      "\u001b[32m[01/18 21:22:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/18 21:22:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/18 21:22:49 d2.data.common]: \u001b[0mSerializing 1584 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/18 21:22:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.51 MiB\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Load the trained model\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "# Set up evaluator\n",
    "evaluator = COCOEvaluator(\"radar_dynamic_test\", cfg, False, output_dir=\"./output/\")\n",
    "test_loader = build_detection_test_loader(cfg, \"radar_dynamic_test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 21:23:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 1584 batches\n",
      "\u001b[32m[01/18 21:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/1584. Dataloading: 0.0006 s/iter. Inference: 0.0548 s/iter. Eval: 0.0001 s/iter. Total: 0.0555 s/iter. ETA=0:01:27\n",
      "\u001b[32m[01/18 21:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 101/1584. Dataloading: 0.0007 s/iter. Inference: 0.0548 s/iter. Eval: 0.0001 s/iter. Total: 0.0556 s/iter. ETA=0:01:22\n",
      "\u001b[32m[01/18 21:23:30 d2.evaluation.evaluator]: \u001b[0mInference done 191/1584. Dataloading: 0.0008 s/iter. Inference: 0.0548 s/iter. Eval: 0.0001 s/iter. Total: 0.0557 s/iter. ETA=0:01:17\n",
      "\u001b[32m[01/18 21:23:35 d2.evaluation.evaluator]: \u001b[0mInference done 281/1584. Dataloading: 0.0008 s/iter. Inference: 0.0549 s/iter. Eval: 0.0001 s/iter. Total: 0.0558 s/iter. ETA=0:01:12\n",
      "\u001b[32m[01/18 21:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 370/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:01:07\n",
      "\u001b[32m[01/18 21:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 459/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0560 s/iter. ETA=0:01:03\n",
      "\u001b[32m[01/18 21:23:51 d2.evaluation.evaluator]: \u001b[0mInference done 549/1584. Dataloading: 0.0008 s/iter. Inference: 0.0551 s/iter. Eval: 0.0001 s/iter. Total: 0.0560 s/iter. ETA=0:00:57\n",
      "\u001b[32m[01/18 21:23:56 d2.evaluation.evaluator]: \u001b[0mInference done 639/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0560 s/iter. ETA=0:00:52\n",
      "\u001b[32m[01/18 21:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 729/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:00:47\n",
      "\u001b[32m[01/18 21:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 819/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:00:42\n",
      "\u001b[32m[01/18 21:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 909/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:00:37\n",
      "\u001b[32m[01/18 21:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 999/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:00:32\n",
      "\u001b[32m[01/18 21:24:21 d2.evaluation.evaluator]: \u001b[0mInference done 1089/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:00:27\n",
      "\u001b[32m[01/18 21:24:26 d2.evaluation.evaluator]: \u001b[0mInference done 1179/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:00:22\n",
      "\u001b[32m[01/18 21:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 1268/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0559 s/iter. ETA=0:00:17\n",
      "\u001b[32m[01/18 21:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 1357/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0560 s/iter. ETA=0:00:12\n",
      "\u001b[32m[01/18 21:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 1446/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0560 s/iter. ETA=0:00:07\n",
      "\u001b[32m[01/18 21:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 1535/1584. Dataloading: 0.0008 s/iter. Inference: 0.0550 s/iter. Eval: 0.0001 s/iter. Total: 0.0560 s/iter. ETA=0:00:02\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:28.481411 (0.056036 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:26 (0.055048 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.31 seconds.\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.476\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.162\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.299\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.302\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 21.872 | 47.557 | 16.227 |  nan  |  nan  | 21.876 |\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[01/18 21:24:49 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category     | AP     | category   | AP     | category   | AP    |\n",
      "|:-------------|:-------|:-----------|:-------|:-----------|:------|\n",
      "| Forklift+KLT | 14.772 | Robotnik   | 23.759 | Forklift   | 0.941 |\n",
      "| Workstation  | 48.016 |            |        |            |       |\n",
      "OrderedDict([('bbox', {'AP': 21.872030598806543, 'AP50': 47.55726198347684, 'AP75': 16.227391948835436, 'APs': nan, 'APm': nan, 'APl': 21.875895951949197, 'AP-Forklift+KLT': 14.771940833558858, 'AP-Robotnik': 23.759432711067838, 'AP-Forklift': 0.9405940594059405, 'AP-Workstation': 48.01615479119353})])\n"
     ]
    }
   ],
   "source": [
    "results = inference_on_dataset(predictor.model, test_loader, evaluator)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/18 21:24:57 d2.data.datasets.coco]: \u001b[0mLoaded 1584 images in COCO format from /home/dartagnan-dev/sahil-dev/model_testing/Detectron2_test/images/test/_annotations.coco.json\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1584 is out of bounds for axis 0 with size 1584",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m y_scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(all_labels), cfg\u001b[38;5;241m.\u001b[39mMODEL\u001b[38;5;241m.\u001b[39mROI_HEADS\u001b[38;5;241m.\u001b[39mNUM_CLASSES))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (pred_class, pred_score) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_preds):\n\u001b[0;32m---> 31\u001b[0m     \u001b[43my_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_class\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m pred_score\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, true_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_labels):\n\u001b[1;32m     34\u001b[0m     y_true[i, true_class] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1584 is out of bounds for axis 0 with size 1584"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_predictions(predictor, dataset_name):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for d in DatasetCatalog.get(dataset_name):\n",
    "        img = cv2.imread(d[\"file_name\"])\n",
    "        outputs = predictor(img)\n",
    "        \n",
    "        pred_classes = outputs[\"instances\"].pred_classes.cpu().numpy()\n",
    "        pred_scores = outputs[\"instances\"].scores.cpu().numpy()\n",
    "        \n",
    "        gt_classes = [ann[\"category_id\"] for ann in d[\"annotations\"]]\n",
    "        \n",
    "        all_preds.extend(list(zip(pred_classes, pred_scores)))\n",
    "        all_labels.extend(gt_classes)\n",
    "    \n",
    "    return all_preds, all_labels\n",
    "\n",
    "all_preds, all_labels = evaluate_predictions(predictor, \"radar_dynamic_test\")\n",
    "\n",
    "# Prepare data for PR and F1 curves\n",
    "y_true = np.zeros((len(all_labels), cfg.MODEL.ROI_HEADS.NUM_CLASSES))\n",
    "y_scores = np.zeros((len(all_labels), cfg.MODEL.ROI_HEADS.NUM_CLASSES))\n",
    "\n",
    "for i, (pred_class, pred_score) in enumerate(all_preds):\n",
    "    y_scores[i, pred_class] = pred_score\n",
    "\n",
    "for i, true_class in enumerate(all_labels):\n",
    "    y_true[i, true_class] = 1\n",
    "\n",
    "# Generate PR curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(cfg.MODEL.ROI_HEADS.NUM_CLASSES):\n",
    "    precision, recall, _ = precision_recall_curve(y_true[:, i], y_scores[:, i])\n",
    "    plt.plot(recall, precision, label=f'Class {i}')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.savefig('pr_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate F1 curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(cfg.MODEL.ROI_HEADS.NUM_CLASSES):\n",
    "    f1_scores = [f1_score(y_true[:, i], y_scores[:, i] > threshold) for threshold in np.arange(0, 1, 0.01)]\n",
    "    plt.plot(np.arange(0, 1, 0.01), f1_scores, label=f'Class {i}')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Threshold')\n",
    "plt.legend()\n",
    "plt.savefig('f1_curve.png')\n",
    "plt.close()\n",
    "\n",
    "# Generate confusion matrix\n",
    "y_pred = np.argmax(y_scores, axis=1)\n",
    "cm = confusion_matrix(np.argmax(y_true, axis=1), y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Evaluation complete. PR curve, F1 curve, and confusion matrix have been saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
